{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Whole Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import time\n",
    "\n",
    "mpl.rcParams['figure.dpi']= 100 \n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>Label</th>\n",
       "      <th>region2kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BrA03.01G007200</td>\n",
       "      <td>NonCircadian</td>\n",
       "      <td>ATCGATTTGTGAATCCTAACTATGTATATATTGTGAATCTGGGTTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BrA03.01G008300</td>\n",
       "      <td>Circadian</td>\n",
       "      <td>GATGCTTGTCGCTCAAGGTAAAGCCTTCCACGGGTTTGTAATAAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BrA03.01G012800</td>\n",
       "      <td>Circadian</td>\n",
       "      <td>TAAAACTGATTTCAGTAAGTGCAGCAACTTCTATTCTCTCTTTTCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BrA03.01G012900</td>\n",
       "      <td>Circadian</td>\n",
       "      <td>GTGAAGACTTTACTTTGAATCTAAAGAGGTGACACCTTTGTTTTTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BrA03.01G013500</td>\n",
       "      <td>NonCircadian</td>\n",
       "      <td>ACGTGTTGGGTGTTTGTCTTTGGCAGGTACAATTTTATGCCGTTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>BraR500.10G282300</td>\n",
       "      <td>Circadian</td>\n",
       "      <td>ACGGTTCGCTTCGATTTTGAGGCCATCCATTTTTCTCCCTTTTTAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>BraR500.10G284500</td>\n",
       "      <td>NonCircadian</td>\n",
       "      <td>AAAAAGGGTTCGAGAATGTTCGATGGCTGTGAGGTTAAAACCCTAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>BraR500.10G286700</td>\n",
       "      <td>Circadian</td>\n",
       "      <td>TAGAGAGAGTCATAGAAGGAGTTTATATAGGGAACTCTCTCTGGCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>BraR500.10G289400</td>\n",
       "      <td>NonCircadian</td>\n",
       "      <td>CTCAAATACTTCGGCTATTGCTTCCCGACAAATATAATCATTTACG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>BraR500.10G290200</td>\n",
       "      <td>NonCircadian</td>\n",
       "      <td>GGCATCTGACATTATTGTCGAGACAGCAGAGGCATTCCTGCCTAAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3995 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   gene         Label  \\\n",
       "0       BrA03.01G007200  NonCircadian   \n",
       "1       BrA03.01G008300     Circadian   \n",
       "3       BrA03.01G012800     Circadian   \n",
       "2       BrA03.01G012900     Circadian   \n",
       "4       BrA03.01G013500  NonCircadian   \n",
       "...                 ...           ...   \n",
       "2622  BraR500.10G282300     Circadian   \n",
       "3065  BraR500.10G284500  NonCircadian   \n",
       "2623  BraR500.10G286700     Circadian   \n",
       "3066  BraR500.10G289400  NonCircadian   \n",
       "3067  BraR500.10G290200  NonCircadian   \n",
       "\n",
       "                                              region2kb  \n",
       "0     ATCGATTTGTGAATCCTAACTATGTATATATTGTGAATCTGGGTTT...  \n",
       "1     GATGCTTGTCGCTCAAGGTAAAGCCTTCCACGGGTTTGTAATAAGG...  \n",
       "3     TAAAACTGATTTCAGTAAGTGCAGCAACTTCTATTCTCTCTTTTCT...  \n",
       "2     GTGAAGACTTTACTTTGAATCTAAAGAGGTGACACCTTTGTTTTTC...  \n",
       "4     ACGTGTTGGGTGTTTGTCTTTGGCAGGTACAATTTTATGCCGTTAG...  \n",
       "...                                                 ...  \n",
       "2622  ACGGTTCGCTTCGATTTTGAGGCCATCCATTTTTCTCCCTTTTTAA...  \n",
       "3065  AAAAAGGGTTCGAGAATGTTCGATGGCTGTGAGGTTAAAACCCTAG...  \n",
       "2623  TAGAGAGAGTCATAGAAGGAGTTTATATAGGGAACTCTCTCTGGCT...  \n",
       "3066  CTCAAATACTTCGGCTATTGCTTCCCGACAAATATAATCATTTACG...  \n",
       "3067  GGCATCTGACATTATTGTCGAGACAGCAGAGGCATTCCTGCCTAAA...  \n",
       "\n",
       "[3995 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the regions -----------\n",
    "\n",
    "# CircadianRegions = '../output/CircadianRegions_2kb.csv'\n",
    "Regions = '../output/circANDnoncirc_Regions_2kb.csv'\n",
    "Regions = pd.read_csv(Regions)\n",
    "\n",
    "#********************************************************\n",
    "#           TESTING ONLY!!! (comment!)\n",
    "# Regions = Regions.sample(frac=0.5, replace=False, random_state=5461) # Sample a fraction of the df\n",
    "#********************************************************\n",
    "\n",
    "# get colnames\n",
    "# Regions.columns.tolist()\n",
    "\n",
    "# Prepare data -----------\n",
    "# data_df = Regions[['gene','JTK_adjphase','region2kb']] # keep relevant cols\n",
    "data_df = Regions[['gene','Label','region2kb']] # keep relevant cols\n",
    "data_df = data_df.sort_values('gene') # make sure df is sorted by gene\n",
    "# CircadianRegions = None\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "data_df['Label'] = label_encoder.fit_transform(data_df['Label'])\n",
    "\n",
    "# Tokenize and pad DNA sequences (T=1, A=2, C=3, G=4)\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(data_df['region2kb'])\n",
    "sequences = tokenizer.texts_to_sequences(data_df['region2kb'])\n",
    "X = pad_sequences(sequences)\n",
    "y = data_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.1 ms, sys: 19 ms, total: 78.2 ms\n",
      "Wall time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.2 ms, sys: 1.83 ms, total: 91 ms\n",
      "Wall time: 38.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=X.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 3s 23ms/step - loss: 0.6891 - accuracy: 0.6004 - val_loss: 0.6608 - val_accuracy: 0.6220\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.5897 - accuracy: 0.6508 - val_loss: 0.6819 - val_accuracy: 0.6120\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.4012 - accuracy: 0.8398 - val_loss: 0.8274 - val_accuracy: 0.5770\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.1317 - accuracy: 0.9715 - val_loss: 1.1413 - val_accuracy: 0.5507\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0379 - accuracy: 0.9962 - val_loss: 1.3696 - val_accuracy: 0.5532\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 1.5477 - val_accuracy: 0.5645\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 1.6869 - val_accuracy: 0.5682\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0042 - accuracy: 0.9984 - val_loss: 1.7966 - val_accuracy: 0.5770\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 1.8576 - val_accuracy: 0.5607\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 1.9313 - val_accuracy: 0.5695\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0023 - accuracy: 0.9984 - val_loss: 1.9743 - val_accuracy: 0.5632\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 2.0295 - val_accuracy: 0.5657\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 2.0860 - val_accuracy: 0.5670\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0018 - accuracy: 0.9984 - val_loss: 2.1396 - val_accuracy: 0.5707\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.1788 - val_accuracy: 0.5682\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 4.8388e-04 - accuracy: 1.0000 - val_loss: 2.2210 - val_accuracy: 0.5682\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 4.0201e-04 - accuracy: 1.0000 - val_loss: 2.2640 - val_accuracy: 0.5695\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 3.4418e-04 - accuracy: 1.0000 - val_loss: 2.2930 - val_accuracy: 0.5682\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 2.9846e-04 - accuracy: 1.0000 - val_loss: 2.3301 - val_accuracy: 0.5682\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 2.6155e-04 - accuracy: 1.0000 - val_loss: 2.3597 - val_accuracy: 0.5695\n",
      "CPU times: user 4min 43s, sys: 5.62 s, total: 4min 48s\n",
      "Wall time: 44.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2b1636c10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step - loss: 2.3597 - accuracy: 0.5695\n",
      "Test Loss: 2.3597\n",
      "Test Accuracy: 56.95%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 3, ..., 3, 1, 1],\n",
       "       [4, 2, 1, ..., 2, 2, 4],\n",
       "       [1, 2, 2, ..., 1, 3, 2],\n",
       "       [4, 1, 4, ..., 1, 1, 1],\n",
       "       [2, 3, 4, ..., 2, 3, 3]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sequences for the first 5 genes, for example\n",
    "gene_sequences = data_df['region2kb'].iloc[:5]\n",
    "sequences = tokenizer.texts_to_sequences(gene_sequences)\n",
    "X_pred = pad_sequences(sequences, maxlen=X.shape[1])\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "              Gene Predicted Label\n",
      "0  BrA03.01G007200    NonCircadian\n",
      "1  BrA03.01G008300       Circadian\n",
      "3  BrA03.01G012800       Circadian\n",
      "2  BrA03.01G012900       Circadian\n",
      "4  BrA03.01G013500    NonCircadian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanbarreto/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:153: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Predicitons\n",
    "predictions = model.predict(X_pred)\n",
    "\n",
    "# Convert predictions to class labels (0 or 1)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Map numerical labels back to original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Get the gene names for the first 5 genes\n",
    "gene_names = data_df['gene'].iloc[:5]\n",
    "\n",
    "# Create a DataFrame to display gene names and predicted labels\n",
    "predictions_df = pd.DataFrame({'Gene': gene_names, 'Predicted Label': predicted_labels})\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- **Precision:** Precision is the ratio of correctly predicted positive observations (True Positives) to the total predicted positive observations (True Positives + False Positives). It measures the accuracy of positive predictions.\n",
    "\n",
    "- **Recall:** Recall is the ratio of correctly predicted positive observations (True Positives) to the total actual positive observations (True Positives + False Negatives). It measures the ability of the model to identify all relevant instances.\n",
    "\n",
    "- **F1-Score:** The F1-score is the harmonic mean of precision and recall. It provides a balanced assessment of a binary classification model, where an F1 score above 0.9 indicates exceptional performance with both high precision and recall, while an F1 score below 0.3 suggests poor model performance with significant false positives and difficulty in correctly identifying positive instances.\n",
    "\n",
    "- **ROC-AUC Score:** ROC-AUC (Receiver Operating Characteristic - Area Under the Curve) measures the area under the ROC curve, which is a plot of the True Positive Rate (recall) against the False Positive Rate at various threshold settings. It indicates the model's ability to distinguish between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38       302\n",
      "           1       0.64      0.71      0.67       497\n",
      "\n",
      "    accuracy                           0.57       799\n",
      "   macro avg       0.53      0.53      0.52       799\n",
      "weighted avg       0.55      0.57      0.56       799\n",
      "\n",
      "ROC-AUC Score: 0.5424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Assuming you already have predictions for the test data\n",
    "# For example:\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) based on a threshold (e.g., 0.5)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequences as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb2b2370610>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the regions\n",
    "Regions = '../output/circANDnoncirc_Regions_2kb.csv'\n",
    "data_df = pd.read_csv(Regions)\n",
    "\n",
    "# Sort the dataframe by gene for consistency\n",
    "data_df = data_df.sort_values('gene')\n",
    "\n",
    "# Define a function to one-hot encode a sequence\n",
    "def one_hot_encode_sequence(sequence):\n",
    "    bases = ['A', 'T', 'C', 'G']\n",
    "    one_hot_encoded = np.zeros((len(bases), len(sequence)))\n",
    "    for i, base in enumerate(sequence):\n",
    "        if base in bases:\n",
    "            one_hot_encoded[bases.index(base), i] = 1\n",
    "    return one_hot_encoded\n",
    "\n",
    "# Example\n",
    "one_hot_encode_sequence('AGTCGTCCAGTGGG')\n",
    "plt.imshow(one_hot_encode_sequence('AGTCGTCCAGTGGG'),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to the 'region2kb' column\n",
    "data_df['one_hot_encoded'] = data_df['region2kb'].apply(one_hot_encode_sequence)\n",
    "\n",
    "# Or convert them to a list of arrays\n",
    "one_hot_encoded_sequences = data_df['one_hot_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 154 ms, sys: 381 ms, total: 535 ms\n",
      "Wall time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert the list of one-hot encoded sequences to a 3D numpy array\n",
    "# Each sequence is a 2D matrix (4, 2000), and you have a list of these matrices\n",
    "X = np.array(one_hot_encoded_sequences)\n",
    "\n",
    "# Convert labels to numerical values (if they are not already)\n",
    "y = data_df['Label'].map({'Circadian': 1, 'NonCircadian': 0}).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(4, 2000, 1))) \n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))  # Added padding\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))  \n",
    "\n",
    "# Flatten the 2D feature maps to 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification, so one output neuron with sigmoid activation\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Reshape input data to match the expected shape (add a channel dimension)\n",
    "X_train = X_train.reshape(X_train.shape[0], 4, 2000, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 4, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 8s 71ms/step - loss: 0.7789 - accuracy: 0.6014 - val_loss: 0.6630 - val_accuracy: 0.6220\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.6635 - accuracy: 0.6058 - val_loss: 0.6677 - val_accuracy: 0.6220\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 0.6156 - accuracy: 0.6477 - val_loss: 0.6777 - val_accuracy: 0.6220\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 0.4159 - accuracy: 0.8404 - val_loss: 0.8032 - val_accuracy: 0.6258\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 0.1500 - accuracy: 0.9675 - val_loss: 0.9550 - val_accuracy: 0.5857\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.0308 - accuracy: 0.9987 - val_loss: 1.3074 - val_accuracy: 0.6033\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4428 - val_accuracy: 0.5745\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5572 - val_accuracy: 0.5770\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6401 - val_accuracy: 0.5707\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.7096 - val_accuracy: 0.5782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2748aa8b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 21ms/step - loss: 1.7096 - accuracy: 0.5782\n",
      "Test Loss: 1.709625482559204\n",
      "Test Accuracy: 0.5782227516174316\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       497\n",
      "           1       0.44      0.42      0.43       302\n",
      "\n",
      "    accuracy                           0.58       799\n",
      "   macro avg       0.55      0.55      0.55       799\n",
      "weighted avg       0.57      0.58      0.58       799\n",
      "\n",
      "ROC-AUC Score: 0.5658\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) based on a threshold (e.g., 0.5)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Convert the list of one-hot encoded sequences to a 3D numpy array\n",
    "# Each sequence is a 2D matrix (4, 2000), and you have a list of these matrices\n",
    "X = np.array(one_hot_encoded_sequences)\n",
    "\n",
    "# Convert labels to numerical values (if they are not already)\n",
    "y = data_df['Label'].map({'Circadian': 1, 'NonCircadian': 0}).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(4, 2000, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "\n",
    "# Flatten the 2D feature maps to 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Adding dropout with a rate of 0.3 to prevent overfitting\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a custom learning rate\n",
    "custom_optimizer = Adam(learning_rate=0.0001)  # Adjust the learning rate here\n",
    "model.compile(loss='binary_crossentropy', optimizer=custom_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Reshape input data to match the expected shape (add a channel dimension)\n",
    "X_train = X_train.reshape(X_train.shape[0], 4, 2000, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 4, 2000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 8s 72ms/step - loss: 0.6768 - accuracy: 0.5989 - val_loss: 0.6637 - val_accuracy: 0.6220\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 0.6685 - accuracy: 0.6051 - val_loss: 0.6701 - val_accuracy: 0.6220\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 0.6640 - accuracy: 0.6061 - val_loss: 0.6611 - val_accuracy: 0.6220\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 0.6459 - accuracy: 0.6142 - val_loss: 0.6619 - val_accuracy: 0.6220\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 0.6265 - accuracy: 0.6289 - val_loss: 0.6755 - val_accuracy: 0.6220\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.5920 - accuracy: 0.6674 - val_loss: 0.6611 - val_accuracy: 0.6208\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.5597 - accuracy: 0.7237 - val_loss: 0.6595 - val_accuracy: 0.6283\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.5198 - accuracy: 0.7581 - val_loss: 0.6644 - val_accuracy: 0.6108\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.4539 - accuracy: 0.8195 - val_loss: 0.7365 - val_accuracy: 0.6208\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.4129 - accuracy: 0.8389 - val_loss: 0.6968 - val_accuracy: 0.6008\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.6968 - accuracy: 0.6008\n",
      "Test Loss: 0.6968007683753967\n",
      "Test Accuracy: 0.6007509231567383\n",
      "CPU times: user 8min 3s, sys: 10 s, total: 8min 13s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71       497\n",
      "           1       0.46      0.30      0.36       302\n",
      "\n",
      "    accuracy                           0.60       799\n",
      "   macro avg       0.55      0.54      0.54       799\n",
      "weighted avg       0.58      0.60      0.58       799\n",
      "\n",
      "ROC-AUC Score: 0.5572\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary labels (0 or 1) based on a threshold (e.g., 0.5)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate and print classification report\n",
    "print(classification_report(y_test, predicted_labels))\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating the search for hyperparameters\n",
    "(Not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fb1e0197430>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:812\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    809\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    810\u001b[0m n_splits \u001b[39m=\u001b[39m cv_orig\u001b[39m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[0;32m--> 812\u001b[0m base_estimator \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator)\n\u001b[1;32m    814\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, pre_dispatch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_dispatch)\n\u001b[1;32m    816\u001b[0m fit_and_score_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    817\u001b[0m     scorer\u001b[39m=\u001b[39mscorers,\n\u001b[1;32m    818\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    825\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m__sklearn_clone__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(estimator):\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[39m=\u001b[39;49msafe)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:98\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[1;32m    103\u001b[0m             )\n\u001b[1;32m    105\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[1;32m    106\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fb1e0197430>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [10, 20, 30],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4],\n",
    "}\n",
    "\n",
    "# Create the model (define the architecture)\n",
    "model = Sequential()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and corresponding model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fb274b2fe50>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto@umn.edu/My Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X52sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m random_search \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_distributions\u001b[39m=\u001b[39mparam_dist, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Fit the random search to your data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X52sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m random_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X52sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Get the best hyperparameters and corresponding model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X52sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m best_params \u001b[39m=\u001b[39m random_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:812\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    809\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    810\u001b[0m n_splits \u001b[39m=\u001b[39m cv_orig\u001b[39m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[0;32m--> 812\u001b[0m base_estimator \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator)\n\u001b[1;32m    814\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, pre_dispatch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_dispatch)\n\u001b[1;32m    816\u001b[0m fit_and_score_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    817\u001b[0m     scorer\u001b[39m=\u001b[39mscorers,\n\u001b[1;32m    818\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    825\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m__sklearn_clone__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(estimator):\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[39m=\u001b[39;49msafe)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:98\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[1;32m    103\u001b[0m             )\n\u001b[1;32m    105\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[1;32m    106\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fb274b2fe50>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Define hyperparameters and their distributions\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.001, 0.1),\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': randint(10, 30),\n",
    "    'dropout_rate': uniform(0.2, 0.4),\n",
    "}\n",
    "\n",
    "# Create the model (define the architecture)\n",
    "model = Sequential()\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the random search to your data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and corresponding model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fb1e01cbb20>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto@umn.edu/My Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X53sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m bayes_search \u001b[39m=\u001b[39m BayesSearchCV(estimator\u001b[39m=\u001b[39mmodel, search_spaces\u001b[39m=\u001b[39msearch_space, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X53sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Fit the Bayesian search to your data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X53sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m bayes_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X53sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Get the best hyperparameters and corresponding model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/joanbarreto/Library/CloudStorage/GoogleDrive-jbarreto%40umn.edu/My%20Drive/PhD/Projects/CircadianTF/code/full_sequence.ipynb#X53sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m best_params \u001b[39m=\u001b[39m bayes_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/skopt/searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs_ \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_kwargs)\n\u001b[0;32m--> 466\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, groups\u001b[39m=\u001b[39;49mgroups, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    468\u001b[0m \u001b[39m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:812\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    809\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    810\u001b[0m n_splits \u001b[39m=\u001b[39m cv_orig\u001b[39m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[0;32m--> 812\u001b[0m base_estimator \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator)\n\u001b[1;32m    814\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs, pre_dispatch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_dispatch)\n\u001b[1;32m    816\u001b[0m fit_and_score_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    817\u001b[0m     scorer\u001b[39m=\u001b[39mscorers,\n\u001b[1;32m    818\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    825\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:76\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m__sklearn_clone__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(estimator):\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39m__sklearn_clone__()\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m _clone_parametrized(estimator, safe\u001b[39m=\u001b[39;49msafe)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/base.py:98\u001b[0m, in \u001b[0;36m_clone_parametrized\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[1;32m    103\u001b[0m             )\n\u001b[1;32m    105\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[1;32m    106\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7fb1e01cbb20>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    'learning_rate': Real(0.001, 0.1, 'log-uniform'),\n",
    "    'batch_size': Integer(32, 128),\n",
    "    'epochs': Integer(10, 30),\n",
    "    'dropout_rate': Real(0.2, 0.4),\n",
    "}\n",
    "\n",
    "# Create the model (define the architecture)\n",
    "model = Sequential()\n",
    "\n",
    "# Create a BayesSearchCV object\n",
    "bayes_search = BayesSearchCV(estimator=model, search_spaces=search_space, scoring='accuracy', cv=3, n_iter=10)\n",
    "\n",
    "# Fit the Bayesian search to your data\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and corresponding model\n",
    "best_params = bayes_search.best_params_\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
